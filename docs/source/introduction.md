# Introduction

The aim of this project is to create Zeppelin, the Zephyr AI Profiling Library,
which allows the user to capture, analyze and report runtime performance
metrics for AI/ML inference workloads.

This documentation describes the following aspects of the project:
* {doc}`library` - describes how to build and test the profiling middleware
* {doc}`configuration` - describes build-time and runtime configuration
* {doc}`memory_profiling` - describes memory profiling along with memory events
* {doc}`code_scopes` - describes usage of tracing code scopes
* {doc}`ctf_to_tef` - describes how traces are converted and processed
* {doc}`visual_interface` - describes a tool for trace visualization
